{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "collective-custom",
   "metadata": {},
   "source": [
    "# To train up a Model with the .wav dataset. Run through this Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-investor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-15 08:59:07--  https://zenodo.org/record/4682101/files/dataset.zip\n",
      "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
      "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2496387986 (2.3G) [application/octet-stream]\n",
      "Saving to: ‘dataset.zip’\n",
      "\n",
      "dataset.zip           9%[>                   ] 234.03M  3.02MB/s    eta 13m 59s"
     ]
    }
   ],
   "source": [
    "#Download Dataset\n",
    "!wget https://zenodo.org/record/4682101/files/dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "executive-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unzip Dataset\n",
    "!unzip dataset.zip > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "descending-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Required Libraries\n",
    "from matplotlib import cm\n",
    "import os.path\n",
    "import random\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "from feature_extract import *\n",
    "from train import Model\n",
    "from tflite_op import *\n",
    "from feature_extract import *\n",
    "\n",
    "if tf.test.is_built_with_cuda():\n",
    "    from tensorflow.compat.v1 import ConfigProto\n",
    "    from tensorflow.compat.v1 import InteractiveSession\n",
    "    config = ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = InteractiveSession(config=config)\n",
    "else:\n",
    "    sess = InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "noble-bonus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Commands:  39\n"
     ]
    }
   ],
   "source": [
    "#!unzip dataset.zip > 0\n",
    "\"\"\" \n",
    "    Read Samples directory into an Array Excluding irrelivant directories\n",
    "\"\"\"\n",
    "data_dir = pathlib.Path('dataset')\n",
    "\n",
    "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "commands = commands[commands != 'validation_list.txt']\n",
    "commands = commands[commands != \"_background_noise_\"]\n",
    "commands = commands[commands != 'LICENSE']\n",
    "commands = commands[commands != '.DS_Store']\n",
    "commands = commands[commands != 'README.md']\n",
    "commands = commands[commands != 'testing_list.txt']\n",
    "commands = commands[commands != '.ipynb_checkpoints']\n",
    "# commands = commands[commands != 'silence']\n",
    "commands = list(commands)\n",
    "print(\"Number of Commands: \", len(commands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opened-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r dataset/_background_noise_\n",
    "# !rm -r dataset/silence\n",
    "model_dir = pathlib.Path('checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-operation",
   "metadata": {},
   "source": [
    "# We are creating a List of the Words that you want to tarin the Model. Please leave the Silence and the Unknown Index as they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rotary-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_commands = [\"silence\", \"unknown\", \"on\", \"off\", \"fan\", \"heater\", \"light\"] # Enter Your Required Labels for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "blond-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_percent = 0.7 # Percentage of Data available for Training\n",
    "validation_percent = 0.20 # Percentage of Data available for Validation\n",
    "testing_percent = 0.10 # Percentage of Data available for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "balanced-evolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silence 75\n",
      "fan 332\n",
      "heater 332\n",
      "off 3958\n",
      "light 351\n",
      "on 4071\n",
      "unknown 4071\n"
     ]
    }
   ],
   "source": [
    "train_files = []\n",
    "val_files = []\n",
    "test_files= []\n",
    "unknown = []\n",
    "high = 0\n",
    "\n",
    "for com in commands:\n",
    "    search_path = os.path.join(data_dir, com, '*.wav')\n",
    "    files = gfile.Glob(search_path)\n",
    "    if com in training_commands:\n",
    "        n_of_samples = len(files)\n",
    "        if n_of_samples >= high:\n",
    "            high = n_of_samples\n",
    "        train_percent = int(n_of_samples * training_percent) # Percentage of Data available for Training\n",
    "        val_percent = int(n_of_samples*validation_percent) # Percentage of Data available for Validation\n",
    "        test_percent = int(n_of_samples*testing_percent) # Percentage of Data available for Testitraining_percent\n",
    "        print(com, n_of_samples)\n",
    "        train_files += files[:train_percent]\n",
    "        val_files += files[train_percent:val_percent+train_percent]\n",
    "        test_files += files[val_percent+train_percent:]\n",
    "    else:\n",
    "        unknown += files\n",
    "\n",
    "np.random.shuffle(unknown)      \n",
    "unknown = unknown[:high]\n",
    "n_of_samples = len(unknown)\n",
    "train_percent = int(n_of_samples * training_percent) # Percentage of Data available for Training\n",
    "val_percent = int(n_of_samples*validation_percent) # Percentage of Data available for Validation\n",
    "test_percent = int(n_of_samples*testing_percent) # Percentage of Data available for Testitraining_percent\n",
    "train_files += files[:train_percent]\n",
    "val_files += files[train_percent:val_percent+train_percent]\n",
    "test_files += files[val_percent+train_percent:]\n",
    "        \n",
    "print(\"unknown\", len(unknown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hundred-julian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples:  8493\n",
      "validation Samples:  1822\n",
      "test Samples:  917\n"
     ]
    }
   ],
   "source": [
    "print(\"training samples: \", len(train_files))\n",
    "print(\"validation Samples: \", len(val_files))\n",
    "print(\"test Samples: \", len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-robertson",
   "metadata": {},
   "source": [
    "## Create Model and Model Layers. You can increase the CNN filters to desired values to increase accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "valid-circuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'silence', 1: 'unknown', 2: 'on', 3: 'off', 4: 'fan', 5: 'heater', 6: 'light'}\n"
     ]
    }
   ],
   "source": [
    "model = Model(first_conv_filter = 8, model_dir=\"checkpoints\", commands= training_commands , sess = sess) # Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "strange-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comment out to load from checkpoint, you can also pass in path to checkpoint\n",
    "#model.load_checkpoint()\n",
    "#model.load_checkpoint(path=\"checkpoint/model_checkpoint.ckpt-15000\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "moderate-exclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/replica:0/task:0/device:GPU:0', '/replica:0/task:0/device:GPU:1')\n",
      "Step #0: learning rate 0.001000, accuracy 5.5%, cross entropy 2.155438\n",
      "Step 0: Validation accuracy = 40.0% (Val Size=1024), Validation loss = 1.859394\n",
      "Step #1000: learning rate 0.001000, accuracy 77.7%, cross entropy 0.613008\n",
      "Step 1000: Validation accuracy = 77.3% (Val Size=1024), Validation loss = 0.674524\n",
      "Step #2000: learning rate 0.001000, accuracy 84.4%, cross entropy 0.541491\n",
      "Step 2000: Validation accuracy = 77.6% (Val Size=1024), Validation loss = 0.603156\n",
      "Step #3000: learning rate 0.001000, accuracy 86.3%, cross entropy 0.405746\n",
      "Step 3000: Validation accuracy = 83.4% (Val Size=1024), Validation loss = 0.485173\n",
      "Step #4000: learning rate 0.001000, accuracy 85.9%, cross entropy 0.388513\n",
      "Step 4000: Validation accuracy = 83.8% (Val Size=1024), Validation loss = 0.476771\n",
      "Step #5000: learning rate 0.001000, accuracy 85.5%, cross entropy 0.475024\n",
      "Step 5000: Validation accuracy = 83.6% (Val Size=1024), Validation loss = 0.464842\n",
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/python/training/saver.py:968: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Step #6000: learning rate 0.001000, accuracy 85.2%, cross entropy 0.435330\n",
      "Step 6000: Validation accuracy = 85.1% (Val Size=1024), Validation loss = 0.451325\n",
      "Step #7000: learning rate 0.001000, accuracy 91.4%, cross entropy 0.280464\n",
      "Step 7000: Validation accuracy = 85.3% (Val Size=1024), Validation loss = 0.443358\n",
      "Step #8000: learning rate 0.001000, accuracy 86.7%, cross entropy 0.405661\n",
      "Step 8000: Validation accuracy = 87.3% (Val Size=1024), Validation loss = 0.404331\n",
      "Step #9000: learning rate 0.001000, accuracy 91.0%, cross entropy 0.289078\n",
      "Step 9000: Validation accuracy = 85.0% (Val Size=1024), Validation loss = 0.414111\n",
      "Step #10000: learning rate 0.000100, accuracy 86.7%, cross entropy 0.364960\n",
      "Step 10000: Validation accuracy = 85.7% (Val Size=1024), Validation loss = 0.425444\n",
      "Step #11000: learning rate 0.000100, accuracy 88.3%, cross entropy 0.346749\n",
      "Step 11000: Validation accuracy = 86.5% (Val Size=1024), Validation loss = 0.393925\n",
      "Step #12000: learning rate 0.000100, accuracy 88.3%, cross entropy 0.312636\n",
      "Step 12000: Validation accuracy = 86.4% (Val Size=1024), Validation loss = 0.411994\n",
      "Step #13000: learning rate 0.000100, accuracy 91.4%, cross entropy 0.283774\n",
      "Step 13000: Validation accuracy = 86.7% (Val Size=1024), Validation loss = 0.397441\n",
      "Step #14000: learning rate 0.000100, accuracy 89.5%, cross entropy 0.279839\n",
      "Step 14000: Validation accuracy = 86.7% (Val Size=1024), Validation loss = 0.404342\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "history = model.train(learn_rate=[0.001, 0.0001], dropout_rate=0.5, save_step=1000, eval_step=1000,\n",
    "                      batch_size=256, training_time=15000, rate_step=10000, display_step=1000, \n",
    "                      train_data=train_files, Validation_data=val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "handy-mistake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(211)\n",
    "plt.plot(history['categorical_accuracy'])\n",
    "plt.plot(history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val'],loc='upper left')# summarize history for loss \n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val'],loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "molecular-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = model.get_next_batch(200, file_path = test_files) # Grab 2000 files from Test files for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "social-circuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1960"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stopped-queue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 85.5%, Validation loss = 0.431981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.855, 0.43198094)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(data, label) # Evaluate on Data # Please note "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-remains",
   "metadata": {},
   "source": [
    "# Let us See the Accuracy on Test Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "substantial-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model accuracy is 85.714286% (Number of test samples=917)\n"
     ]
    }
   ],
   "source": [
    "grab = int(len(test_files)/5)\n",
    "fro = 0\n",
    "correct = 0\n",
    "for i in range(5):\n",
    "    data, label = model.get_next_batch(int(len(test_files)/5), test_files[fro:grab])\n",
    "    predictions = model.predict(data)[0]\n",
    "    correct+=np.sum(predictions == label)\n",
    "    fro = grab\n",
    "    grab+=int(len(test_files)/5)\n",
    "print(' Model accuracy is %f%% (Number of test samples=%d)' % (\n",
    "        (correct * 100) / len(test_files), len(test_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-spelling",
   "metadata": {},
   "source": [
    "# Here we are Saving the Model for a reload using tf.saved_model.load, Serving Signature is set to Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "agreed-trinidad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model_checkpoint.ckpt-15000\n",
      "WARNING:tensorflow:From /home/jovyan/train.py:414: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: Model/model_pb/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "model.save_pb_model(file_name = \"Model/model_pb\",  first_conv_filter= 8, frequency_size=40, time_size=49, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-reach",
   "metadata": {},
   "source": [
    "# The Next Lines of code introduces you to TensorFlow LITE (TFLITE) and Tensorflow LITE MICRO (TFLITE MICRO)\n",
    "### TFLITE for Android Devices and Micro-Computers\n",
    "### TFLITE Micro for Micro-controllers and Embedded Devices with low power and generally requiring int8 computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "better-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories and tflite micro libraries\n",
    "from tflite_op import *\n",
    "rep_size = 100\n",
    "float_model_tflite=\"Model/tfFloat\"\n",
    "quant_model_tflite= \"Model/tflite\"\n",
    "pb_model_dir = \"Model/model_pb\"\n",
    "tflite_micro = \"Model/tflite_micro.cc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "regulation-reality",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Invoking the TF1 implementation of TFLiteConverter because eager is disabled. Consider enabling eager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: Reshape_4:0, shape: (1, 1960), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: Reshape_4:0, shape: (1, 1960), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: labels_softmax:0, shape: (1, 7), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: labels_softmax:0, shape: (1, 7), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/lite/python/util.py:326: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/lite/python/util.py:326: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/python/framework/convert_to_constants.py:856: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/python/framework/convert_to_constants.py:856: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: Reshape_4:0, shape: (1, 1960), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: Reshape_4:0, shape: (1, 1960), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: labels_softmax:0, shape: (1, 7), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: labels_softmax:0, shape: (1, 7), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float model is 116224 bytes\n"
     ]
    }
   ],
   "source": [
    "# See tflite_op for implementation. Save TFLITE MODEL FOR FLOAT VALUE COMPUTATION\n",
    "save_float_model(model_path=pb_model_dir, save_path=float_model_tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "soviet-resident",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Invoking the TF1 implementation of TFLiteConverter because eager is disabled. Consider enabling eager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: Reshape_4:0, shape: (1, 1960), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: Reshape_4:0, shape: (1, 1960), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: labels_softmax:0, shape: (1, 7), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: labels_softmax:0, shape: (1, 7), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: Reshape_4:0, shape: (1, 1960), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: Reshape_4:0, shape: (1, 1960), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: labels_softmax:0, shape: (1, 7), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: labels_softmax:0, shape: (1, 7), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model is 31120 bytes\n"
     ]
    }
   ],
   "source": [
    "# # See tflite_op for implementation. Save TFLITE MODEL FOR INT8 VALUE COMPUTATION\n",
    "save_quantized_model(model_path=pb_model_dir, save_path=quant_model_tflite, rep_files=train_files, rep_data=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-delicious",
   "metadata": {},
   "source": [
    "# Now Let us Test the Accuracy from TFLITE... See Implmentation in tflite_op.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fluid-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our data from our wanted commands\n",
    "commands_files =[]\n",
    "for com in [\"on\", \"off\", \"heater\", \"fan\", \"light\"]:\n",
    "    search_path = os.path.join(\"dataset\", com, '*.wav')\n",
    "    file = gfile.Glob(search_path)\n",
    "    np.random.shuffle(file)\n",
    "    commands_files += file\n",
    "# Preprocess using the Micro_process Implementation\n",
    "data, labels = model.get_next_batch(len(commands_files), commands_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abandoned-uzbekistan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1960, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(data[i], axis=1).astype(np.float32).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-developer",
   "metadata": {},
   "source": [
    "# Great Result, 91% on our Wanted words with TFLITE saved as Float: See Result below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "portuguese-prisoner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Float model accuracy is 91.231756% (Number of test samples=9044)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "correct_predictions = 0\n",
    "for i in range(len(data)):\n",
    "    correct_predictions += (predict_float(data[i], float_model_tflite) == labels[i])\n",
    "   \n",
    "\n",
    "print(' Float model accuracy is %f%% (Number of test samples=%d)' % (\n",
    "        (correct_predictions * 100) / len(data), len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-compensation",
   "metadata": {},
   "source": [
    "# Great Result, 91% on our Wanted words with TFLITE saved as INT8: See Result below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "olive-supplement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Int8 model accuracy is 91.032729% (Number of test samples=9044)\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "for i in range(len(data)):\n",
    "    correct_predictions += (predict_quantized(data[i], quant_model_tflite ) == labels[i])\n",
    "   \n",
    "\n",
    "print(' Int8 model accuracy is %f%% (Number of test samples=%d)' % (\n",
    "        (correct_predictions * 100) / len(data), len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-gathering",
   "metadata": {},
   "source": [
    "## For Embedded Devices, Let us covert to TFLITE Micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ongoing-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i {quant_model_tflite} > {tflite_micro}\n",
    "REPLACE_TEXT = quant_model_tflite.replace('/', '_').replace('.', '_')\n",
    "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {tflite_micro}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-celebrity",
   "metadata": {},
   "source": [
    "# Holla!!! You have Just Created a MODEL that can be deployed for Speech Recognition on Embedded Devices. Next is to locate the file Model/tflite_micro.cc and this is the Model for deployment to our Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "scenic-stanford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(labels[30])\n",
    "\n",
    "predict_quantized(data[30], quant_model_tflite )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip model.zip -r Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ethical-picture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: checkpath/ (stored 0%)\n",
      "  adding: checkpath/model.pbtxt (deflated 95%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-12000.meta (deflated 87%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-15000.data-00000-of-00001 (deflated 7%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-13000.index (deflated 37%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-15000.meta (deflated 87%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-15000.index (deflated 37%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-11000.data-00000-of-00001 (deflated 7%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-13000.meta (deflated 87%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-14000.meta (deflated 87%)\n",
      "  adding: checkpath/checkpoint (deflated 80%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-14000.index (deflated 37%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-13000.data-00000-of-00001 (deflated 7%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-11000.index (deflated 37%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-11000.meta (deflated 87%)\n",
      "  adding: checkpath/.ipynb_checkpoints/ (stored 0%)\n",
      "  adding: checkpath/.ipynb_checkpoints/model-checkpoint.pbtxt (deflated 95%)\n",
      "  adding: checkpath/.ipynb_checkpoints/checkpoint-checkpoint (deflated 78%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-12000.data-00000-of-00001 (deflated 7%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-14000.data-00000-of-00001 (deflated 7%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-12000.index (deflated 37%)\n",
      "  adding: checkpath/commands_labels.txt (deflated 34%)\n"
     ]
    }
   ],
   "source": [
    "!zip checkpoint.zip -r checkpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "relevant-chrome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  check.zip\n",
      "   creating: work/model/\n",
      "  inflating: work/model/model.pbtxt  \n",
      "  inflating: work/model/model_checkpoint.ckpt-7000.index  \n",
      "  inflating: work/model/model_checkpoint.ckpt-8000.meta  \n",
      "  inflating: work/model/model_checkpoint.ckpt-9000.meta  \n",
      "  inflating: work/model/model_checkpoint.ckpt-9000.index  \n",
      "  inflating: work/model/model_checkpoint.ckpt-8000.data-00000-of-00001  \n",
      "  inflating: work/model/model_checkpoint.ckpt-7000.data-00000-of-00001  \n",
      "  inflating: work/model/model_checkpoint.ckpt-8000.index  \n",
      "  inflating: work/model/checkpoint   \n",
      "  inflating: work/model/model_checkpoint.ckpt-9000.data-00000-of-00001  \n",
      "  inflating: work/model/model_checkpoint.ckpt-10000.data-00000-of-00001  \n",
      "  inflating: work/model/model_checkpoint.ckpt-6000.meta  \n",
      "  inflating: work/model/model_checkpoint.ckpt-6000.data-00000-of-00001  \n",
      "  inflating: work/model/model_checkpoint.ckpt-7000.meta  \n",
      "  inflating: work/model/model_checkpoint.ckpt-6000.index  \n",
      "  inflating: work/model/model_checkpoint.ckpt-10000.index  \n",
      "  inflating: work/model/commands_labels.txt  \n",
      "  inflating: work/model/model_checkpoint.ckpt-10000.meta  \n"
     ]
    }
   ],
   "source": [
    "!unzip check.zip -d work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-exhibit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-colon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-thomson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-tourist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-retrieval",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (λ)",
   "language": "python",
   "name": "lambda-stack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
