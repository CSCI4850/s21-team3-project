{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "following-vertex",
   "metadata": {},
   "source": [
    "# To train up a Model with the .wav dataset. Run through this Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download Dataset\n",
    "!wget https://zenodo.org/record/4682101/files/dataset.zip?download=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unzip Dataset\n",
    "!unzip dataset.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "formed-investing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Required Libraries\n",
    "from matplotlib import cm\n",
    "import os.path\n",
    "import random\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "from feature_extract import *\n",
    "from train import Model\n",
    "from tflite_op import *\n",
    "from feature_extract import *\n",
    "\n",
    "if tf.test.is_built_with_cuda():\n",
    "    from tensorflow.compat.v1 import ConfigProto\n",
    "    from tensorflow.compat.v1 import InteractiveSession\n",
    "    config = ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = InteractiveSession(config=config)\n",
    "else:\n",
    "    sess = InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "patient-sewing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Commands:  38\n"
     ]
    }
   ],
   "source": [
    "#!unzip dataset.zip > 0\n",
    "\"\"\" \n",
    "    Read Samples directory into an Array Excluding irrelivant directories\n",
    "\"\"\"\n",
    "data_dir = pathlib.Path('dataset')\n",
    "\n",
    "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "commands = commands[commands != 'validation_list.txt']\n",
    "commands = commands[commands != \"_background_noise_\"]\n",
    "commands = commands[commands != 'LICENSE']\n",
    "commands = commands[commands != '.DS_Store']\n",
    "commands = commands[commands != 'README.md']\n",
    "commands = commands[commands != 'testing_list.txt']\n",
    "commands = commands[commands != '.ipynb_checkpoints']\n",
    "commands = commands[commands != 'silence']\n",
    "commands = list(commands)\n",
    "print(\"Number of Commands: \", len(commands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "protected-finding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'dataset/_background_noise_': No such file or directory\n",
      "rm: cannot remove 'dataset/silence': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r dataset/_background_noise_\n",
    "!rm -r dataset/silence\n",
    "model_dir = pathlib.Path('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intellectual-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_path = os.path.join(data_dir, \"*\", '*.wav') # Collect all available ./wav files into a python list\n",
    "files = gfile.Glob(search_path)\n",
    "np.random.shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "actual-barcelona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples:  75098\n",
      "validation Samples:  22529\n",
      "test Samples:  9656\n"
     ]
    }
   ],
   "source": [
    "# Divide file samples into training, Validation and Testing\n",
    "\n",
    "n_of_samples = len(files)\n",
    "train_percent = int(n_of_samples * 0.7) # Percentage of Data available for Training\n",
    "val_percent = int((n_of_samples - train_percent)*0.7) # Percentage of Data available for Validation\n",
    "test_percent = int((n_of_samples - train_percent)*0.3) # Percentage of Data available for Testing\n",
    "\n",
    "train_files = files[:train_percent]\n",
    "val_files = files[train_percent:val_percent+train_percent]\n",
    "test_files= files[val_percent+train_percent:]\n",
    "\n",
    "print(\"training samples: \", len(train_files))\n",
    "print(\"validation Samples: \", len(val_files))\n",
    "print(\"test Samples: \", len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-premium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "danish-squad",
   "metadata": {},
   "source": [
    "## Create Model and Model Layers. You can increase the CNN filters to desired values to increase accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "modular-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(first_conv_filter = 128, second_conv_filter = 64, model_dir=\"checkpath\", commands= commands, sess = sess) # Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "difficult-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comment out to load from checkpoint, you can also pass in path to checkpoint\n",
    "#model.load_checkpoint()\n",
    "#model.load_checkpoint(path=\"model/model_checkpoint.ckpt-10000\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "paperback-belle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/replica:0/task:0/device:GPU:0', '/replica:0/task:0/device:GPU:1')\n",
      "Step #0: learning rate 0.010000, accuracy 2.7%, cross entropy 4.647210\n",
      "Step 0: Validation accuracy = 3.7% (Val Size=512), Validation loss = 3.979101\n",
      "Step #1000: learning rate 0.010000, accuracy 72.3%, cross entropy 0.877669\n",
      "Step 1000: Validation accuracy = 74.8% (Val Size=512), Validation loss = 1.163367\n",
      "Step #2000: learning rate 0.010000, accuracy 80.9%, cross entropy 0.585962\n",
      "Step 2000: Validation accuracy = 81.1% (Val Size=512), Validation loss = 0.764981\n",
      "Step #3000: learning rate 0.010000, accuracy 82.8%, cross entropy 0.574525\n",
      "Step 3000: Validation accuracy = 80.9% (Val Size=512), Validation loss = 0.717540\n",
      "Step #4000: learning rate 0.010000, accuracy 89.1%, cross entropy 0.370905\n",
      "Step 4000: Validation accuracy = 85.4% (Val Size=512), Validation loss = 0.631443\n",
      "Step #5000: learning rate 0.010000, accuracy 87.1%, cross entropy 0.388354\n",
      "Step 5000: Validation accuracy = 86.3% (Val Size=512), Validation loss = 0.549975\n",
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/python/training/saver.py:968: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Step #6000: learning rate 0.010000, accuracy 91.0%, cross entropy 0.266476\n",
      "Step 6000: Validation accuracy = 88.7% (Val Size=512), Validation loss = 0.531844\n",
      "Step #7000: learning rate 0.010000, accuracy 91.8%, cross entropy 0.259930\n",
      "Step 7000: Validation accuracy = 87.9% (Val Size=512), Validation loss = 0.475388\n",
      "Step #8000: learning rate 0.010000, accuracy 93.4%, cross entropy 0.199593\n",
      "Step 8000: Validation accuracy = 84.0% (Val Size=512), Validation loss = 0.552903\n",
      "Step #9000: learning rate 0.010000, accuracy 93.8%, cross entropy 0.211160\n",
      "Step 9000: Validation accuracy = 87.1% (Val Size=512), Validation loss = 0.470839\n",
      "Step #10000: learning rate 0.000100, accuracy 93.4%, cross entropy 0.215178\n",
      "Step 10000: Validation accuracy = 86.9% (Val Size=512), Validation loss = 0.445307\n",
      "Step #11000: learning rate 0.000100, accuracy 95.3%, cross entropy 0.149876\n",
      "Step 11000: Validation accuracy = 88.9% (Val Size=512), Validation loss = 0.410310\n",
      "Step #12000: learning rate 0.000100, accuracy 92.6%, cross entropy 0.224032\n",
      "Step 12000: Validation accuracy = 87.1% (Val Size=512), Validation loss = 0.478024\n",
      "Step #13000: learning rate 0.000100, accuracy 94.5%, cross entropy 0.221134\n",
      "Step 13000: Validation accuracy = 89.8% (Val Size=512), Validation loss = 0.394515\n",
      "Step #14000: learning rate 0.000100, accuracy 94.1%, cross entropy 0.159043\n",
      "Step 14000: Validation accuracy = 87.3% (Val Size=512), Validation loss = 0.450617\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "history = model.train(learn_rate=[0.01, 0.0001], dropout_rate=0.5, save_step=1000, eval_step=1000,\n",
    "                      batch_size=256, training_time=15000, rate_step=10000, display_step=1000, \n",
    "                      train_data=train_files, Validation_data=val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "lucky-combat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdeZwcdZ3w8c+37+m5j5yTkEk4AxESCBgElUNd5FZYiBwPqCvrsSuw4oLr48qzj7vLs6u7KyIgIoprAJFD0QXkkEPkTCCQQMBwJGRyTiZz9hx9fZ8/qmam58r0ZLqnume+79erX1X1q6qub/VM17d/v6r6lagqxhhjTKHxeR2AMcYYMxJLUMYYYwqSJShjjDEFyRKUMcaYgmQJyhhjTEGyBGWMMaYgWYIyZh+JyM9E5DtZLrtJRD6W75iMmUosQRljjClIlqCMmeZEJOB1DMaMxBKUmdLcprWvi8hrIhITkZ+IyCwReUhEOkTkMRGpzlj+TBF5XURaReRJEVmcMW+ZiLzsrvdLIDJkW6eLyFp33WdF5PAsYzxNRF4RkXYR2SIi1w6Zf7z7fq3u/Evd8hIR+Z6IbBaRNhF5xi07QUQaR/gcPuaOXysi94jIL0SkHbhURI4RkefcbWwXkRtEJJSx/mEi8qiI7BGRnSLyDyIyW0S6RKQ2Y7mjRKRJRILZ7Lsxe2MJykwH5wAfBw4CzgAeAv4BqMP5DnwVQEQOAu4ErgBmAA8CvxWRkHuw/jXw30AN8Cv3fXHXPRK4DfhroBb4EfCAiISziC8G/C+gCjgN+JKInO2+735uvD9wY1oKrHXX+y5wFPAhN6a/B9JZfiZnAfe421wFpIAr3c/kWOBk4MtuDOXAY8DDwFzgAOBxVd0BPAmcl/G+FwF3qWoiyziMGZUlKDMd/EBVd6rqVuCPwAuq+oqq9gL3A8vc5c4H/kdVH3UPsN8FSnASwAogCPyXqiZU9R7gpYxtfAH4kaq+oKopVb0d6HXX2ytVfVJV16lqWlVfw0mSH3VnXwg8pqp3utttVtW1IuIDPgdcrqpb3W0+6+5TNp5T1V+72+xW1TWq+ryqJlV1E06C7YvhdGCHqn5PVXtUtUNVX3Dn3Y6TlBARP/AZnCRuzIRZgjLTwc6M8e4Rpsvc8bnA5r4ZqpoGtgD17rytOrh35c0Z4wuAr7lNZK0i0grMd9fbKxH5oIg84TaNtQFfxKnJ4L7HOyOsVofTxDjSvGxsGRLDQSLyOxHZ4Tb7/UsWMQD8BjhURBbh1FLbVPXFfYzJmEEsQRkzYBtOogFARATn4LwV2A7Uu2V99ssY3wL8s6pWZbyiqnpnFtu9A3gAmK+qlcDNQN92tgD7j7DObqBnlHkxIJqxH36c5sFMQx9jcBPwJnCgqlbgNIGOFQOq2gPcjVPTuxirPZkcsgRlzIC7gdNE5GT3JP/XcJrpngWeA5LAV0UkICKfBo7JWPfHwBfd2pCISKl78UN5FtstB/aoao+IHANckDFvFfAxETnP3W6tiCx1a3e3Af8hInNFxC8ix7rnvP4MRNztB4H/DYx1LqwcaAc6ReQQ4EsZ834HzBaRK0QkLCLlIvLBjPk/By4FzgR+kcX+GpMVS1DGuFT1LZzzKT/AqaGcAZyhqnFVjQOfxjkQt+Ccr7ovY93VOOehbnDnv+0um40vA/8kIh3AP+Ikyr73fR84FSdZ7sG5QOIId/ZVwDqcc2F7gP8H+FS1zX3PW3FqfzFg0FV9I7gKJzF24CTbX2bE0IHTfHcGsAPYCJyYMf9POBdnvOyevzImJ8QeWGiMmSgR+QNwh6re6nUsZuqwBGWMmRARORp4FOccWofX8Zipw5r4jDH7TERux7lH6gpLTibXrAZljDGmIFkNyhhjTEEquk4i6+rqtKGhweswjDHG5MiaNWt2q+rQe/WKL0E1NDSwevVqr8MwxhiTIyKyeaRya+IzxhhTkIquBmWMMRORSKVp707Q3pOkrTvhjifc8WTGeIJQwEddWZi6spA7dF/lIWqiIQL+wv2Nn0orXfEkPhH8PsEnQsAn+Hwy9soFwhKUMdNIOq10JVLEepP0JFKk0uq81Bmm05BMp0mrkkozaH7aHU+m1Z3vDJOpjPluuTMP/IJzcPS5B0f3YNn/EmeeXwS/3x32HUz9GcsPWg984syLxZO0d7uJpsdNNmMkn654aq+fUdAvVJYEKY8EiSfTNHX2Ek8Of4qJCNREQ/0Jq64sTG3pwPiMjGRWWxomFBhfMlNVuuKpjH0bO6G2dSfo6EnS3p2gozc56ntnfv7O5w0Bv8/9vBn09xjrb/elE/bnxINnjmvfsjUlElQikaCxsZGenh6vQ8m7SCTCvHnzCAbteXDTRTyZprM3Saw3OWSYGlY2MO7Mi8UHymK9KWLxJFP9zhIRKA8HqIwGqYg4r0V1ZVSUBKiIBKksCVJREqSiJOCMR5zpvvFI0Edmn8CqSkdvkt0dvezujLO7s9d5dfSyOxZ3y3t55f1Wdnf2jpoAK0uCQ2piISJB/+Dk0zOQaNp7kqTSe/9jlYUDVEQC7v4EmVcddffP2bfSUADF/VGR7vvRkXZ/SND/A6PvB0f/cu4PjuSQ8aE/QlJpJZ/1sSmRoBobGykvL6ehoWHQP9ZUo6o0NzfT2NjIwoULvQ5nWkqk0uxo66GxpZvuRJJ4Mk08pcSTaRKptDOdTBN3xxOZw1SaeFKJp9Ik3GUSqTS9Q5dLpkmknOaZWG+KeCq7ZxCGAj7KwgFKw35KQwHKwgFqSkPMr4lSFgpQGg5QFvZTGnbGS4L+Qb+I+5qA+mo8I9VaAj4fPh/DajV9v64DGev6RJwDYEaNa2iNLJkeqIkNn7/32lxalWgoMCzRlIcDOW3GEpGBRDfsOrPhuuJJdnfEaepLZJ29NA9KbHE2bG+nqbOX3kR6ULKsjoZoqC0dlkwH9m9gX8sjgYJuYsyFKZGgenp6pnxyAueLUltbS1NTk9ehTFnptLKzw0lAW/Z0sWVPN40tXWxpccZ3tPeM+as2U8AnhAI+gn4foYCPkDsM+jPK/U5iCUUHlgv6fURD/mFJpSw8kGjKwkFKw/7+suAUP1gVi2gowH61AfarjY69cK6lU9DVDLEm6NwFvR1QUg2ldRCtg2gN+PyTH9c+mhIJCpjyyalPse5nIpXmrR0dvNbYxrqtrTR19FLe9wsxo4li4Fej+wsyGqQslLtfxKpKcyzOlj1dThJqGUhCjS3dbG3pHlZjmVvuZ3FlkjPm9LJw/zjzwt3MCnYRCgbwB8L4Q+GBYTBMMBTpH/qCYfCHnFcgDP4g+N0ynyUUTyV6oKcVetqcV3ffeOtAufghXA6RSghXuOMVznjfMFwB/jweSlOJgYQTaxo83rkLYrugs8kZdjWD7q3GLU6SitY5SasvcZXWQekMiNZmlM3wPKFNmQRlCkcqrby9q5PXGltZt7WNVxvb2LC9vf9Ec2VJkPqqEjp6O/pP8u7tvMhI5xQGJbERzimEAj62tfY4tZ89XWxpcZLQzpYOQvFWqqWTGumgmg7mhbv5i5Ju5oa6mTEnRg0dlKfbKUm2Eejdg/R2OA/f2J3jD8oXGEheQxNYIOQcJKr2g+oFUOW+qhc4B5FC/qGSTkP3Hoi5H5j4nHj7hsiQMt8oZUPXzVzOnR/vdJLJoOQyNOGMUp7q3ft+BCLOwT4VH3ufg1EneQ1KXH3JrHKExFbulIOTWIYlnYzk090y+jZLZziv6gUwbzmUzYTSmVA2wxmGy531u3ZDrNkdNjl/m65m2PWmM93dwvBnWOJ83iXV7nbqBhJY6Qw3idXCvKOd/9M8sASVA62trdxxxx18+ctfHtd6p556KnfccQdVVVV5iiz/0mllU3PMSURbnNrR+q3tdCecE8Vl4QBL6iu49EMNfKC+kiPmVTG/pmRQTTCdVjrjyYGTw7FeYl2ddMZidMVidHd30dvdSU93C/HeLuLd3SRbu0nEu+mId9OZ6mU3CcLECZMgLAmi9FIlnRxABx/0dVLn76RKOyjxdTkPSs+kQBeQLHN/XdZCyQyIHjIwHa2BkszxamfdZK/zCzflDpO9zgGt75U5newrH23ZjPnJuHNw2vaKc7DPFCx1k9Z+A0krczxSmZ8/tqpzYO/YAR3bM4bbM6bdVzqRnxjGQ/zOZ1FS5QwjlVBRPzDeX17lvoYsG3Cf8ZjocZrKetud/e9td6Z72t0ydzhovAPatw2UJWLZxRyuGEg6Mw6ChuPdpDNjhORTlrvPKpV0klSsyU1iuweaCmO7BxJc01uw+U/QtYf+hHbWjbDswtzFksESVA60trZy4403DktQqVQKv3/06vGDDz6Y79BySlVpbOl2a0WtrGtsY93WNjp6nMtZI0Efh82t5Pyj53P4vEoOn1fFotoovthO2PMONL8Aa96B5necA1qyF5I9+JK9VCR7qEj2Mi/ZDenRL48dxsew283TviApXxgtqcZXWoe/bCESrR2cYPoTUUZZYKyHznqktwNa34eWzdC62R2+74xv+hPEh3QiHqnMSFwLhozPh1Dp8G3Eu0ZIOkMT0Q5IdA1fN1wJ5bOhYo5zQC2fDeVz3Jqez6mFqALqjrvTfePDynWU8qFlOAfp/iQzJMGEynJT0wxGnFdZFldIjCaVdP5OmQmsp93Zn/6kMwOCJROPd1/4A04M2e5jOjWQ0Mpm5S0sS1A5cM011/DOO++wdOlSgsEgZWVlzJkzh7Vr1/LGG29w9tlns2XLFnp6erj88su57LLLgIFumzo7O/nkJz/J8ccfz7PPPkt9fT2/+c1vKCnx6J/VtbO9h1e3OM10r7nJaE/Mae4I+oXFcyo484i5HD6vkqV1yv6+HQRa3nWS0Ttvw4vvwJ53nWaYPv4w1CyCirnOlzEQcV9hdzo8MN0/HKV80PID83w+/9TqIiVcDrMOc15DqToHiv7EtXkgmTW9BRsfheSQ2y9KZzjJKhSFjp1O4ultG/7egRI38cyFucucpNOXfPrHZ4+c8Mxg/oBT6+6reRc7n3/gHFYeTbkE9X9++zpvbGvP6XseOreCb58xwsHBdd1117F+/XrWrl3Lk08+yWmnncb69ev7LwW/7bbbqKmpobu7m6OPPppzzjmH2traQe+xceNG7rzzTn784x9z3nnnce+993LRRRflbB96Eqm93uDX3pOkrWtg/tu7OtnV4bTR+33CgTPLOPWgMo6tbmNJZDf1qa0EWt+D5rfhz28PbicXv/OLvWZ/WHAc1O7vvg5wmliK6CqigicyUCOcu2z4fFXnXMagBOaOJ7qcZqRFHx2SeNzkE6ks7HNdZsqbcgmqEBxzzDGD7lO6/vrruf/++wHYsmULGzduHJagFi5cyNKlSwE46qij2LRp0/A3VkWTvSR7Y7z1yK10xdN0J9N0xdPEEmm6Eu64Ox2Lp+jsdXoOiKcgjaBI/1AR0upDgWAgQEk4QDQUZL9wgJNndXN4w24aZDs1PVvwt7wLG7YPjqei3kk8h57tJJ/aA5zpqgXOSX7jPREon+W85h/jdTTGjMuUS1B7q+lMltLSgSaPJ598kscee4znnnuOaDTKCSecMGKPF+HwwPkPv99Pd1eXc44m0U06HiPVG8OX7MZPmkB3Mwc/+7XsA/K7r7Ek3VcX0FchitY5SWf/k5xhjVsTqlnkNBEZY0yeTLkE5YXy8nI6OkZ+2nVbWxvV1dVEo1HefPNNnn/++VHeRaG7DRJdaGw32tkGu97on5UgRI+UoYESuiPKq596grKwj/Kwn7KQj5KgDxl2IjljOOYJ58wydS4eqF00ddrMjTFFxxJUDtTW1nLcccexZMkSSkpKmDVr4KqWU045hZtvvpnDDz+cgw8+mBUrVkAq5VzBoynYswnamp3aUsu7KJBMJenRAFu1Fg1ECZWUUhYJUh30IyLsam5j8eLFnu2vMcZMBtEi6zly+fLlOvSBhRs2bCjcA3Y6CYlu5zLehPvKuPEvKSG6CNOZDtGlIZL+CGXhEGURp1ubkfraKuj9NcaYcRKRNaq6fGi51aByTdPODW7xmJOUMu5WT/tCJHwRYv4K2pJBujREWvyUhvyURwLUR4JEAr6i7c7IGGNyyRJUrnU2Qcc28AXRYJR4qIrOdIiWRIAu9/7TUMBHeTRIbcTp5NNfRA8QM8aYyZJVghKRe4HbgIdU99oT4fSmisaaSPhLafTNJdaTQlXxiVAaDjC3LEB5OEDIaknGGDOmbGtQNwGfBa4XkV8BP1PVN/MXVpHqaUPSCbala0gGlNrSEOWRAKU57I3bGGOmi6wSlKo+BjwmIpXAZ4BHRWQL8GPgF6paAD1Dek9ju0gQIB2u4KAZOezI0RhjpqGsuywTkVrgUuCvgFeA7wNHAo/mJbJiE+9C4jF2awV1ZQXa6agxxhSRbM9B3QccAvw3cIaq9vV580sRWT36mtNIrIk0QsxfyZzI3j/WsrIyOjs797qMMcZMd9meg7pBVf8w0oyRrl2fdlIJtLuFFi2juqzELoAwxpgcyDZBLRaRl1W1FUBEqoHPqOqN+QuteFx91ZUsmFHOJy79OxZGQ1x77bWICE8//TQtLS0kEgm+853vcNZZZ3kdqjHGFI1sE9QXVPWHfROq2iIiXwAKL0E9dA3sWJfb95z9AfjkdSPP0zTnn/pRvvqtf+NTX/lH/D7h7rvv5uGHH+bKK6+koqKC3bt3s2LFCs4880yrXRljTJayTVA+ERF1+0USET9gz1MA6GnjyMMOYEdzK71tzby6qZnq6mrmzJnDlVdeydNPP43P52Pr1q3s3LmT2bNnex2xMcYUhWwT1O+Bu0XkZpwHLX8ReDhvUU3EaDWdPNHOJuIEOPWsT/PAr+9jx44drFy5klWrVtHU1MSaNWsIBoM0NDSM+JgNY4wxI8s2QV0N/DXwJUCAR4Bb8xVU0Yh3IYkYzVrLxRdewOVf+RK7d+/mqaee4u6772bmzJkEg0GeeOIJNm/e7HW0xhhTVLK9UTeN05vETfkNp7horAlF6AlUcvSy/ejo6KC+vp45c+Zw4YUXcsYZZ7B8+XKWLl3KIYcc4nW4xhhTVLK9D+pA4F+BQ4FIX7mqLspTXIUvlYDuFvZoOTXlJQCsWzdwcUZdXR3PPffciKvaPVDGGDO2bHuS+ClO7SkJnAj8HOem3emrqxlBafNVUlES9DoaY4yZcrJNUCWq+jjOAw43q+q1wEn5C6vAaZp0rIkOLaG8rAyfXTpujDE5l+1FEj0i4gM2isjfAFuBmfkLa/xUdfLuMepuxZdOsoc66qOTe7V9sT0B2Rhj9lW2NagrgCjwVeAo4CLgkrFWEpFTROQtEXlbRK4ZYf4JItImImvd1z+OJ/g+kUiE5ubmSTt4p2NN9GqQQLRyxEey54uq0tzcTCQSGXthY4wpcmPWoNybcs9T1a8DnTjPhRqTu94PgY8DjcBLIvKAqr4xZNE/qurp4wt7sHnz5tHY2EhTU9NE3iY7yTh07qCVMkrL36N9x+QlKHCS8bx58yZ1m8YY44UxE5SqpkTkqMyeJLJ0DPC2qr4LICJ3AWcBQxPUhAWDQRYuXJjrtx1R6t7L6Fn3G66ffxc3ff6wSdmmMcZMR9meg3oF+I37NN1YX6Gq3reXdeqBLRnTjcAHR1juWBF5FdgGXKWqrw9dQEQuAy4D2G+//bIMOQ86diLr7+Xu5Mlc+JEPeBeHMcZMA9kmqBqgmcFX7imwtwQ10hULQ2tgLwMLVLVTRE4Ffg0cOGwl1VuAWwCWL1/u2VUCuuan+DTJH6s+xaUH1HoVhjHGTAvZ9iSR1XmnIRqB+RnT83BqSZnv254x/qCI3Cgidaq6ex+2l1/JOIkXbuVPqSP4i48eZ72SG2NMnmXbk8RPGV77QVU/t5fVXgIOFJGFOJelrwQuGPK+s4GdqqoicgzOVYXNWcY+ud74DaHuJu4NXsZ3l9Z7HY0xxkx52Tbx/S5jPAJ8iiG1oaFUNeneM/V7wA/cpqqvi8gX3fk3A+cCXxKRJNANrBznhRiTpvdPN7I1PYdFx55BJOj3OhxjjJnysm3iuzdzWkTuBB7LYr0HgQeHlN2cMX4DcENWkXqpcTXhnS/z33opX/rQ5FwtaIwx0122NaihDgQ8vJxucsWfvYm4ltBz6PnMLLebZI0xZjJkew6qg8HnoHbgPCNq6uvYgX/Dr7k79TEu/Ijd92SMMZMl2ya+8nwHUqjSL92GaIq1c87jc/WVXodjjDHTRlb99IjIp0SkMmO6SkTOzl9YBSLZS+KFW3kitZTTTzjO62iMMWZaybYjuW+ralvfhKq2At/OT0gF5PX7Cfc282D0TE5ePMvraIwxZlrJ9iKJkRLZvl5gURxU6frjDWxLz2XJh8/G77Mbc40xZjJlW4NaLSL/ISL7i8giEflPYE0+A/Nc40tEd6/jLvkkf3n0tLlg0RhjCka2CepvgTjwS+BunJtqv5KvoApB9zM/pF2jBI+8gLLw1K4sGmNMIcr2Kr4YMOyBg1NW+zZCf/4tq1J/wQUfPtTraIwxZlrK9iq+R0WkKmO6WkR+n7+wvJV44VZE02ze/wLm10S9DscYY6albJv46twr9wBQ1RZgZn5C8liih9RLt/F46kjOPNEuLTfGGK9km6DSItJ/pYCINDBC7+ZTQXr9vUTiLTxV/WmWL6j2OhxjjJm2sj37/03gGRF5yp3+CO4TbqcUVWJP38D2dD3LTzjbnvlkjDEeyqoGpaoPA8uBt3Cu5PsazpV8U8uWFyhveYP7gqdz6uFzvY7GGGOmtWw7i/0r4HKcp+KuBVYAzzH4EfBFr+OpG0hrlOpjLyYUyLb10xhjTD5kexS+HDga2KyqJwLLgKa8ReWFtq1E33mQe/Qkzjv2YK+jMcaYaS/bBNWjqj0AIhJW1TeBKXUU73r2FtA0uw+9hOrSkNfhGGPMtJftRRKN7n1QvwYeFZEWxnjke1FJdCNrfspj6aP49InHeh2NMcYYsu9J4lPu6LUi8gRQCTyct6gmWfLVeyhJtvHynPP5i1nT9tFXxhhTUMbdyZyqPjX2UkVElc6nb2BHej4fOnnqP+LKGGOKxbS/VE03P0tV+5s8GD2Tjxw0w+twjDHGuKZ9N917nvgBfi2l/iOX2I25xhhTQKZ3Dap1C1Wbf8/98jHOXH6A19EYY4zJMK0TVNsfbwZV4kd+lpKQ3+twjDHGZJi+CSrRTXDtz3lUj+asj9ql5cYYU2imbYLqefkuoql2NjZcwOzKiNfhGGOMGWJ6XiShSuyPP+S99H589ON2abkxxhSiaVmDSr33DLWdG3my6tMcPt+e+WSMMYVoWtagmh77PmEtY9FJl3odijHGmFFMvxpUy2Zmbnuc3wU/wccOb/A6GmOMMaPIa4ISkVNE5C0ReVtErhlhvojI9e7810TkyHzGA9D0hx+SVgh88K/w++zGXGOMKVR5a+ITET/wQ+DjQCPwkog8oKpvZCz2SeBA9/VB4CZ3mDe/aj+EXj2fz3/4mHxuxhhjzATl8xzUMcDbqvougIjcBZwFZCaos4Cfq6oCz4tIlYjMUdXt+QrqvL+8kPVbT6ciEszXJowxxuRAPpv46oEtGdONbtl4l8mpurIwJxw8M5+bMMYYkwP5TFAjneDRfVgGEblMRFaLyOqmpqn1pHljjDEjy2cTXyMwP2N6HsOfwpvNMqjqLcAtACLSJCKbJxhbHbB7gu/htWLfh2KPH4p/H4o9fij+fSj2+CE3+7BgpMJ8JqiXgANFZCGwFVgJXDBkmQeAv3HPT30QaBvr/JOqTvihTSKyWlWXT/R9vFTs+1Ds8UPx70Oxxw/Fvw/FHj/kdx/ylqBUNSkifwP8HvADt6nq6yLyRXf+zcCDwKnA20AX8Nl8xWOMMaa45LUnCVV9ECcJZZbdnDGuwFfyGYMxxpjiNP16knDc4nUAOVDs+1Ds8UPx70Oxxw/Fvw/FHj/kcR/EqcQYY4wxhWW61qCMMcYUOEtQxhhjCtK0S1BjdWBbyERkvog8ISIbROR1Ebnc65j2hYj4ReQVEfmd17HsC7dLrntE5E33b3Gs1zGNl4hc6f4PrReRO0WkoB8rLSK3icguEVmfUVYjIo+KyEZ3WNAPdxtlH/7d/T96TUTuF5EqL2Pcm5Hiz5h3lYioiNTlcpvTKkFldGD7SeBQ4DMicqi3UY1LEviaqi4GVgBfKbL4+1wObPA6iAn4PvCwqh4CHEGR7YuI1ANfBZar6hKc20BWehvVmH4GnDKk7BrgcVU9EHjcnS5kP2P4PjwKLFHVw4E/A9+Y7KDG4WcMjx8RmY/TKfj7ud7gtEpQZHRgq6pxoK8D26KgqttV9WV3vAPnwJjXvgtzTUTmAacBt3ody74QkQrgI8BPAFQ1rqqt3ka1TwJAiYgEgCgj9OBSSFT1aWDPkOKzgNvd8duBsyc1qHEaaR9U9RFVTbqTz+P0plOQRvkbAPwn8PeM0E3dRE23BDXpndPmi4g0AMuAF7yNZNz+C+efOe11IPtoEdAE/NRtprxVREq9Dmo8VHUr8F2cX7zbcXpwecTbqPbJrL6eZ9xhsfcC/TngIa+DGA8RORPYqqqv5uP9p1uCyqpz2kInImXAvcAVqtrudTzZEpHTgV2qusbrWCYgABwJ3KSqy4AYhd+0NIh7ruYsYCEwFygVkYu8jWp6E5Fv4jThr/I6lmyJSBT4JvCP+drGdEtQWXVOW8hEJIiTnFap6n1exzNOxwFnisgmnObVk0TkF96GNG6NQKOq9tVc78FJWMXkY8B7qtqkqgngPuBDHse0L3aKyBwAd7jL43j2iYhcApwOXKjFdWPq/jg/cl51v9PzgJdFZHauNjDdElR/B7YiEsI5MfyAxzFlTUQE59zHBlX9D6/jGS9V/YaqzlPVBpzP/g+qWlS/3FV1B7BFRA52i05m8EM4i8H7wAoRibr/UydTZBd6uB4ALnHHLwF+42Es+0RETgGuBs5U1S6v4xkPVV2nqjNVtcH9TjcCR7rfkZyYVgnKPRnZ14HtBuBuVX3d26jG5TjgYpyax1r3darXQU1DfwusEpHXgKXAv3gcz7i4tb97gJeBdTjHgYLuckdE7gSeAw4WkUYR+TxwHfBxEdmIcxXZdV7GOEQrgbgAACAASURBVJZR9uEGoBx41P0+37zXN/HQKPHnd5vFVaM0xhgzXUyrGpQxxpjiYQnKGGNMQbIEZYwxpiBZgjLGGFOQLEEZY4wpSJagjClSInJCsfYIb0w2LEEZY4wpSJagjMkzEblIRF50b8T8kfs8rE4R+Z6IvCwij4vIDHfZpSLyfMbzgard8gNE5DERedVdZ3/37csynk21yu0ZwpgpwRKUMXkkIouB84HjVHUpkAIuBEqBl1X1SOAp4NvuKj8HrnafD7Quo3wV8ENVPQKn37ztbvky4Aqc55stwultxJgpIeB1AMZMcScDRwEvuZWbEpxOTdPAL91lfgHcJyKVQJWqPuWW3w78SkTKgXpVvR9AVXsA3Pd7UVUb3em1QAPwTP53y5j8swRlTH4JcLuqDnpSqoh8a8hye+tzbG/Ndr0Z4ynsO22mEGviMya/HgfOFZGZACJSIyILcL5757rLXAA8o6ptQIuIfNgtvxh4yn3mV6OInO2+R9h9Fo8xU5r92jImj1T1DRH538AjIuIDEsBXcB50eJiIrAHacM5TgfPYiJvdBPQu8Fm3/GLgRyLyT+57/OUk7oYxnrDezI3xgIh0qmqZ13EYU8isic8YY0xBshqUMcaYgmQ1KGOMMQXJEpQxxpiCZAnKGGNMQbIEZYwxpiBZgjLGGFOQLEEZY4wpSJagjDHGFCRLUMYYYwqSJShjjDEFyRKUMcaYgmQJyhiPiMjPROQ7WS67SUQ+NtH3MaaYWIIyxhhTkCxBGWOMKUiWoIzZC7dp7esi8pqIxETkJyIyS0QeEpEOEXlMRKozlj9TRF4XkVYReVJEFmfMWyYiL7vr/RKIDNnW6SKy1l33WRE5fB9j/oKIvC0ie0TkARGZ65aLiPyniOwSkTZ3n5a4804VkTfc2LaKyFX79IEZk0OWoIwZ2znAx4GDgDOAh4B/AOpwvkNfBRCRg4A7gSuAGcCDwG9FJCQiIeDXwH8DNcCv3PfFXfdI4Dbgr4Fa4EfAAyISHk+gInIS8K/AecAcYDNwlzv7E8BH3P2ownmKb7M77yfAX6tqObAE+MN4tmtMPliCMmZsP1DVnaq6Ffgj8IKqvqKqvcD9wDJ3ufOB/1HVR1U1AXwXKAE+BKwAgsB/qWpCVe8BXsrYxheAH6nqC6qaUtXbgV53vfG4ELhNVV924/sGcKyINOA8Kr4cOATnWXAbVHW7u14COFREKlS1RVVfHud2jck5S1DGjG1nxnj3CNN9j26fi1NjAUBV08AWoN6dt1UHPyF0c8b4AuBrbvNeq4i0AvPd9cZjaAydOLWkelX9A3AD8ENgp4jcIiIV7qLnAKcCm0XkKRE5dpzbNSbnLEEZkzvbcBIN4JzzwUkyW4HtQL1b1me/jPEtwD+ralXGK6qqd04whlKcJsOtAKp6vaoeBRyG09T3dbf8JVU9C5iJ0xR59zi3a0zOWYIyJnfuBk4TkZNFJAh8DaeZ7lngOSAJfFVEAiLyaeCYjHV/DHxRRD7oXsxQKiKniUj5OGO4A/isiCx1z1/9C06T5CYROdp9/yAQA3qAlHuO7EIRqXSbJtuB1AQ+B2NywhKUMTmiqm8BFwE/AHbjXFBxhqrGVTUOfBq4FGjBOV91X8a6q3HOQ93gzn/bXXa8MTwOfAu4F6fWtj+w0p1dgZMIW3CaAZtxzpMBXAxsEpF24IvufhjjKRncJG6MMcYUBqtBGWOMKUiWoIwxxhQkS1DGGGMKkiUoY4wxBSngdQDjVVdXpw0NDV6HYYwxJkfWrFmzW1VnDC0vugTV0NDA6tWrvQ7DGGNMjojI5pHKp10TXzqtbNnT5XUYxhhjxjDtEtQ1973GOTc9SzKV9joUY4wxezHtEtTJi2exq6OXJ95q8joUY4wxe1F056BGkkgkaGxspKenZ8xl54ty29lzCcW2s2HDnkmILrcikQjz5s0jGAx6HYoxxuTVlEhQjY2NlJeX09DQwODOokdW09ZNU0cv+8+uIBQonkqkqtLc3ExjYyMLFy70OhxjjMmr4jk670VPTw+1tbVZJSeA6tIQCrR0xfMbWI6JCLW1tVnVFI0xpthNiQQFZJ2cAMIBP2XhAC2xOMXWWe549tMYY4rZlElQ41VTGiKeStPZm/Q6FGOMMSOYtgmqoiRIwCfsiU28ma+1tZUbb7xx3OudeuqptLa2Tnj7xhgzFRVEghIRv4i8IiK/m6xt+kSoioZo70mSmOA9UaMlqFRq7w8lffDBB6mqqprQto0xZqoqiAQFXA5smOyN1pSGUFVaJ3ixxDXXXMM777zD0qVLOfrooznxxBO54IIL+MAHPgDA2WefzVFHHcVhhx3GLbfc0r9eQ0MDu3fvZtOmTSxevJgvfOELHHbYYXziE5+gu7t7QjEZY0yx8/wycxGZB5wG/DPwdxN9v//z29d5Y1v73hfSNIiTm3sSKVShJOQfdfFD51bw7TMOG3X+ddddx/r161m7di1PPvkkp512GuvXr++/FPy2226jpqaG7u5ujj76aM455xxqa2sHvcfGjRu58847+fGPf8x5553Hvffey0UX2VO3jTHTVyHUoP4L+Htg1HY2EblMRFaLyOqmpgn2AJHsgUQ34Fy9F/D7SKuSyuHVfMccc8yg+5Suv/56jjjiCFasWMGWLVvYuHHjsHUWLlzI0qVLATjqqKPYtGlTzuIxxphi5GkNSkROB3ap6hoROWG05VT1FuAWgOXLl+81k+ytpgNAvAt2vwVls6FiDqm08ub2dipKgsyviY57H0ZSWlraP/7kk0/y2GOP8dxzzxGNRjnhhBNGvI8pHA73j/v9fmviM8ZMe17XoI4DzhSRTcBdwEki8ou8bjEUhUgVxHZBKoHfJ1RFg7R1J/a5A9ny8nI6OjpGnNfW1kZ1dTXRaJQ333yT559/fiLRG2PMtOFpglLVb6jqPFVtAFYCf1DV/J94KZ/jnIfq3Ak4F0ukVWntTuzT29XW1nLcccexZMkSvv71rw+ad8opp5BMJjn88MP51re+xYoVKyYcvjHGTAeeXyThiWAEojUQ2w2lMykJhSgJ+tkTi1NbGtqn3hruuOOOEcvD4TAPPfTQiPP6zjPV1dWxfv36/vKrrrpq3Ns3xpipxusmvn6q+qSqnj5pGyyb4ww7twNOLaonkaI7vvd7l4wxxkyOgklQky4QgtI66NoDiR6qokF8kpueJYwxxkzc9E1QAGWznPuhOrbj9/moLAnS2p0glS6uDmSNMWYqmt4Jyh+E0pnQ0wrxroyLJawWZYwxXpveCQqgbCaIHzq2EQ35iQT9tFgznzHGeM4SlM8P5bOgtwOJd1ITDdEVt4sljDHGa5agAKIzwBeE9m1URYOICHvy+LTdsrKyvL23McZMFZagAHw+KJ8NiS4C8Q4qI0Fau+Kk7WIJY4zxzPS8UXck0Vro3AUd26ipOIDW7jht3QmqS0Njrnr11VezYMECvvzlLwNw7bXXIiI8/fTTtLS0kEgk+M53vsNZZ52V770wxpgpY+olqIeugR3r9m3ddAKSPZQGIhyQFKdHiaAfZn8APnndqKutXLmSK664oj9B3X333Tz88MNceeWVVFRUsHv3blasWMGZZ565T71UGGPMdDT1EtRE+AIgfiQVJ+CPEE8qadUx20GXLVvGrl272LZtG01NTVRXVzNnzhyuvPJKnn76aXw+H1u3bmXnzp3Mnj17UnbFGGOK3dRLUHup6WSlpx32vIO/vJ732sLUlYWYU1Uy5mrnnnsu99xzDzt27GDlypWsWrWKpqYm1qxZQzAYpKGhYcTHbBhjjBmZXSQxVLgcQqX4YzupjPho6UqQzuJhhitXruSuu+7innvu4dxzz6WtrY2ZM2cSDAZ54okn2Lx58yQEb4wxU4clqKFEoHwupJPM9HeQTKdpz+IxHIcddhgdHR3U19czZ84cLrzwQlavXs3y5ctZtWoVhxxyyCQEb4wxU8fUa+LLhXAZhCsI9+wm4t+PPbE4VdGxr+Zbt27g4oy6ujqee+65EZfr7OzMWajGGDNV5bQGJSKXi0iFOH4iIi+LyCdyuY1JUzEH0RT1gXY6e5PEk9azhDHGTKZcN/F9TlXbgU8AM4DPAhO8asEjwShEqokmWgiSYk9s3562a4wxZt/kOkH13eRzKvBTVX01oyyvNIsLGcatYjaCUh9op6Urnp9tjFMhxGCMMZMh1wlqjYg8gpOgfi8i5UA6x9sYJhKJ0NzcnPuDd8B5NHx5ug1JxenoSeb2/cdJVWlubiYSiXgahzHGTIZcXyTxeWAp8K6qdolIDU4zX17NmzePxsZGmpqacv/m6RR07KJb23hteyW1ZeHcb2McIpEI8+bN8zQGY4yZDLlOUMcCa1U1JiIXAUcC38/xNoYJBoMsXLgwfxt45Jfosz/glPj/4/arL2F2pdVgjDEm33LdxHcT0CUiRwB/D2wGfp7jbUy+469EQ2X8nf9ufrV6i9fRGGPMtJDrBJVU50TQWcD3VfX7QHmOtzH5ojX4jrucv/CvZt2Lj9tjOIwxZhLkOkF1iMg3gIuB/xERPxDM8Ta8seKL9IZquKTr5zzz9m6vozHGmCkv1wnqfKAX536oHUA98O853oY3wuX4PnoVx/lfZ+1Tv/Y6GmOMmfJymqDcpLQKqBSR04EeVd3rOSgRmS8iT4jIBhF5XUQuz2VMuRT84F/RGprNR7fcRHOH9UxujDH5lOuujs4DXgT+EjgPeEFEzh1jtSTwNVVdDKwAviIih+YyrpwJhOk97usc4XuHNb8v/ms/jDGmkOW6ie+bwNGqeomq/i/gGOBbe1tBVber6svueAewAadpsCDNOv5SGv3zOeiN76Mpb2/cNcaYqSzXCcqnqrsyppvHsw0RaQCWAS8MKb9MRFaLyOq83Iw7Hv4A7y/9OxrSjbz7+E+8jcUYY6awXCeoh0Xk9yJyqYhcCvwP8GA2K4pIGXAvcIXb4Ww/Vb1FVZer6vIZM2bkOOTxW/qJi1mv+1P94vcg2et1OMYYMyXl+iKJrwO3AIcDRwC3qOrVY60nIkGc5LRKVe/LZUz5EA0HeXH/v6EmuZPu5271OhxjjJmScv5EXVW9V1X/TlWvVNX7x1peRAT4CbBBVf8j1/HkyzEnfZpnU4fC0/8OvfYAQmOMybWcJCgR6RCR9hFeHSLSPsbqx+Hc2HuSiKx1X6fmIq58WjKvinurP0dJogV9/kavwzHGmCknJ53Fquo+d2ekqs8wSc+MyrVlH/oEj/zPUZz8zPX4j/4riNZ4HZIxxkwZOW/im07OWjqXG1iJJDrhmf/0OhxjjJlSLEFNQHkkyEGHf5Df6vHoi7dA+zavQzLGmCnDEtQEfeaY+fx7/BzSqSQ89W9eh2OMMVOGJagJOnK/akpmLOLh8Cnwyn9D8zteh2SMMVOCJagJEhFWHrMf17aeStoXhCf+xeuQjDFmSrAElQOfXlZPm7+GZ2rPhfX3wI51XodkjDFFzxJUDlSXhjhlyWy+sfNENFIJj/8TpNNeh2WMMUXNElSOrDx6Plt7Iry+6HOw8RH43kFwz+fhlV9A21avwzPGmKKTkxt1DaxYVMuC2ij/d8/H+OWnFsM7j8M7TzhNfgC1B8L+J8KiE6HheIhUeBuwMcYUOEtQOeLzCecfPZ9/e/gt3jnnNPY/4nxQhV1vOInq3Sed2tSLt4D4Yd5yJ1ktOsEZ9wc93gNjjCksoqpexzAuy5cv19WrV3sdxoh2dfTwoX/9A587fiH/cOri4Qske2HLi06yevcJ2PYKaBpC5U6tatEJTi2r7iCQouz9yRhjxk1E1qjq8qHlVoPKoZnlEU5ePJN71jRy5H7VLKmvoL6qBOlLNoEwLPyw8zr5W9DdAu897SSsd56APz/kLFc+dyBZLToBymZ6sj/GGOMlq0Hl2OpNe7joJy/Qk3Cu4quOBllSX8lhcyv5QH0lS+or2K8mOpC0MrVsGmgOfO8pJ4EBzDxs4PzVgmMhVDpp+2OMMfk2Wg3KElQedMdTvLmjnfVb21i/tZ3129r4884OEinnsy6PBFgy10lWS+orWVJfycLaUny+jKSVTsH2VweaA99/HlJx8Idg3jFQPhuCEQj0vcIZw5Ih05GMZUdbLgI+u6jTGDP5LEF5rDeZ4s87Olm/rY11W9t4fWsbG3Z0EE86Na3SkJ9D57oJa66TtPafUUrA7yaNeBe8/5yTrDb9yaldJXsh2eMOu53zWRPhC0LQTVrBqHOlYbjSHVa4w/KM8QqIVDrDcPlAWajMkp0xJmuWoApQIpVm404nab2+tY3129p5Y1s73YkUAJGgj8VzKgbVtg6cWU4oMMrBP5V0EtWgxNXjvBI9Q8oy5g0tT3RDPAa97dDTPnjY255FIpS9JLSKjIRW6c7PfFUMjAcidrGIMdOAJagikUor7za5Na1Gp3nwjW3tdPYmAQj5fRw4q4yKSBCfD3wiiAg+ccZ9wpBpQTLmDVveN/Ly1dEQC2qj7FcTZUFtKdXRoHPeTHXvyWto2Wjz0omxPwxfICNxjZTMhiS0zLJQqbO+z++8ZOjQNzA/s2wqJ8RUAno7IN7pDNOpwZ9hIOR1hGaasqv4ioTfJxw4q5wDZ5XzqWVOWTqtbGqOsX5bO69vbeON7e30JtIkUkpalbSCusPB0wNl2j9PSafHWD6tdLgJsU95JMCC2igLakrZrzbKgpoo+9XWsaB2AXPqI4PPn41F1amt9Xa6yatjyGtoWcZ05w5o3jgwnezJ4aePm6TchOULuOO+4QnO53fP7ZU4zaGZ48GSjFc284aUZ9Yck70D+9qXWHo7Id6RMd6Z3TJjfVb+cEatd2jyH/pDILNZd0hZIJzbv4mZtqwGZUbUk0jx/p4uNjd3sbk51j/+/p4uGlu6+i/4AKdWN6+mhAVubWtBbdStfZUyv6aEcMCfv0CTcfegPEKi0zSkk05NQVPuMD1kOrN8nMsme5zm0EGvLmeYdKdT8X3br0CJG08WNU1wkly43Dn/15cw+sfL3PGKjPFyJxn3J7QRPr+e9iHz2p2YxuIPDWzfH3RrqkEnqfdPD3n5AxnLBUZf1p8x3xd0tuXvG45jPBAeXO4L7v28qarzt43HBr8SseFl8ZjzuY60/NB1ND38B0B/03dmWUbT+NAfB6Fy5/ObiHR64H8283852TPwP535ylz2sLNh7rIJbd5qUGZcIkE/B80q56BZ5cPmpdLKttZuJ3ntifF+s5vI9nTx4nt7iMVT/cuKwJyKiFvrcmtftVHqysL9tbmUKum0kkrrwLg602lVUmlGKBsyX5VUOkIqHSattQhQFQ1RWxaipjxETWmI2tIwNaWh0c/h5UM6NXry6v/iZx4E3INCPOYcPIclnLKBC1HCZQPlvjz+COijmlGjax85qQ0q63QSbDrpnB9NJweSbjrl7GM6OfiVcuf1L5e5biK7BLmvfIHhySyVcJNKFzCOH/PBqNPMHIw6f59QKYSizj2N/eWlzhcksyWhpx32vOd+fm0DP7TG3F7pkGTmJrJgNOOHVNfg8cz/u1Tvvn1m/jDMOGTCCWo0lqDMuPl9wvyaKPNrohxP3aB5qkpzLM7m5phb++pya18xHn9zJ7s797FGkUPl4QA1ZX1JyxnWlIYHxssGymtLw5SEJnDw9/ndRFKWux3wiohzu0IwAmUzvIlB1TlgpxJOwkr1veLuKzFkOHQ8Pkr5COPJuFMz6UswfUklVOYkm/7xIYkoGM3dVax9NbdBtdn2ITXcjPLMso4dztW/QbeJOVDixFg6c6BstGbmbJut8/zDyBKUySkRoa4sTF1ZmKMW1Ayb39mb5P3mLlq64vhE8PsEv3uxh98nGWUZ4+7FHAPjGUN3XGTw/HRaae1OsCfWS3NnnD2xOM0xZzgw3ktjSzevNbbR0hUf1GyZqSTod5JVWV8yC1ETDREM+BCc47bgxCAiw8v6pt3zSn0Xogxdru/zE8AnEAz4iIb8lAT9lIQClAT9REN+IkE/JSE/UXcYDvhGvvF7KhIZOA9IxOto8k/ETYSlwByvo5l0lqDMpCoLBzh0bv57cvf5pD+ZHJBFT1GqzoUhezozE1mvM56R4Jo742zc2cmeWJxkOu38oHfXd4b53rPhRBicvDLGoyEniZUEA5SEfERDgf5lQgHfyBfTpDOnh19Mkxpjfub79bWK9X1GA+MD5TDw+fUV9k2pZi6rw9aLBAcSdbT/Fejf72goQGnGeOYykeDEEnsqrcTiSbp6U3T2Jon1veIpYr3JgTJ3eqSyvvsg+/6O4PxgyZwemO+WD11+lPXEXaf//8H9UTMwHhil3Pl8SkI+SkIBT38IeZ6gROQU4PuAH7hVVa/zOCQzDYkIFZEgFZEgDXUT60pK3QP90MTVd4AdND5kmb6Dc1qd++S64im64ym6EwPDrniSnkTKmddXPmwZZ7i7Mz6ovG+Y/ecy/PYFf+btC25Nd6TbG/rWzzyADj149o2TUQ4DNcn+9xjloN2bTNMVT9IVd/Y5lc7+F0JmYh+c1Aamk2mlqzdJrC8JxZ3xWG9yXJ9jachPaThAWThANOynNBRgdkWEUMBH390bMDgZD54ePJ9R5+ug6VRa6Umk2NGe6P/79/1vZCbHbPjcz6uk73MKBoiE/Hz1pAM4efGscb1XtjxNUCLiB34IfBxoBF4SkQdU9Q0v4zJmIkQk40BaeE1v6bTSm0wTT6XHuF+OSf/FPBGqSjyV7j8IO69kf5LPnHbKnPFYxnhfcm/u7KI7kcIvQmk4QGnYz9yqiFMjCwcoC2cknJAzvyzszCsdMl0S9I/vNoxJkkylh/2o6Yqn+n/8ZP4QGlzeN+58ZkF//i468roGdQzwtqq+CyAidwFnAZagjMkTn0+cX8FMwpV/k0hECAf8hAN+qqJeR1P4An4f5X4f5ZHCfRad1x2m1QNbMqYb3TJjjDHTnNcJaqR677BGZBG5TERWi8jqpqamSQjLGGOM17xu4msE5mdMzwO2DV1IVW8BbgEQkSYR2TzB7dYBuyf4Hl4r9n0o9vih+Peh2OOH4t+HYo8fcrMPC0Yq9LSrIxEJAH8GTga2Ai8BF6jq63ne7uqRutUoJsW+D8UePxT/PhR7/FD8+1Ds8UN+98HTGpSqJkXkb4Df41xmflu+k5Mxxpji4HUTH6r6IPCg13EYY4wpLF5fJOGVW7wOIAeKfR+KPX4o/n0o9vih+Peh2OOHPO5D0T1uwxhjzPQwXWtQxhhjCpwlKGOMMQVp2iUoETlFRN4SkbdF5Bqv4xkPEZkvIk+IyAYReV1ELvc6pn0hIn4ReUVEfud1LPtCRKpE5B4RedP9WxzrdUzjJSJXuv9D60XkThEp6GdXiMhtIrJLRNZnlNWIyKMistEdVnsZ41hG2Yd/d/+PXhOR+0WkyssY92ak+DPmXSUiKiJ1I627r6ZVgsronPaTwKHAZ0TkUG+jGpck8DVVXQysAL5SZPH3uRzY4HUQE/B94GFVPQQ4giLbFxGpB74KLFfVJTi3eKz0Nqox/Qw4ZUjZNcDjqnog8Lg7Xch+xvB9eBRYoqqH49wT+o3JDmocfsbw+BGR+Tgdfr+f6w1OqwRFRue0qhoH+jqnLQqqul1VX3bHO3AOjEXVd6GIzANOA271OpZ9ISIVwEeAnwCoalxVW72Nap8EgBL3ZvkoI/TgUkhU9Wlgz5Dis4Db3fHbgbMnNahxGmkfVPURVe17jv3zOL3pFKRR/gYA/wn8PSN0UzdR0y1BTZnOaUWkAVgGvOBtJOP2Xzj/zON7GE3hWAQ0AT91mylvFZGJPUBqkqnqVuC7OL94twNtqvqIt1Htk1mquh2cH29AFo+mLGifAx7yOojxEJEzga2q+mo+3n+6JaisOqctdCJSBtwLXKGq7V7Hky0ROR3YpaprvI5lAgLAkcBNqroMiFH4TUuDuOdqzgIWAnOBUhG5yNuopjcR+SZOE/4qr2PJlohEgW8C/5ivbUy3BJVV57SFTESCOMlplare53U843QccKaIbMJpXj1JRH7hbUjj1gg0qmpfzfUenIRVTD4GvKeqTaqaAO4DPuRxTPtip4jMAXCHuzyOZ5+IyCXA6cCFWlw3pu6P8yPnVfc7PQ94WURm52oD0y1BvQQcKCILRSSEc2L4AY9jypo4jzf9CbBBVf/D63jGS1W/oarzVLUB57P/g6oW1S93Vd0BbBGRg92ikym+B2y+D6wQkaj7P3UyRXahh+sB4BJ3/BLgNx7Gsk9E5BTgauBMVe3yOp7xUNV1qjpTVRvc73QjcKT7HcmJaZWg3JORfZ3TbgDuLrLOaY8DLsapeax1X6d6HdQ09LfAKhF5DVgK/IvH8YyLW/u7B3gZWIdzHCjoLndE5E7gOeBgEWkUkc8D1wEfF5GNOFeRXedljGMZZR9uAMqBR93v882eBrkXo8Sf320WV43SGGPMdDGtalDGGGOKhyUoY4wxBckSlDHGmIJkCcoYY0xBsgRljDGmIFmCMqZIicgJxdojvDHZsARljDGmIFmCMibPROQiEXnRvRHzR+7zsDpF5Hsi8rKIPC4iM9xll4rI8xnPB6p2yw8QkcdE5FV3nf3dty/LeDbVKrdnCGOmBEtQxuSRiCwGzgeOU9WlQAq4ECgFXlbVI4GngG+7q/wcuNp9PtC6jPJVwA9V9QicfvO2u+XLgCtwnm+2CKe3EWOmhIDXARgzxZ0MHAW85FZuSnA6NU0Dv3SX+QVwn4hUAlWq+pRbfjvwKxEpB+pV9X4AVe0BcN/vRVVtdKfXAg3AM/nfLWPyzxKUMfklwO2qOuhJqSLyrSHL7a3Psb012/VmjKew77SZQqyJz5j8ehw4V0RmAohIjYgswPnunesucwHwjKq2AS0i8mG3/GLgKfeZX40icrb7HmH3WTzG/P/27tAIgRiIAuhfNJ1QDxKBpgUUVUAr9IBF0gMzOEQQdy3A7TDvyYhMon42mcn+YDWYCAAAAGdJREFUNact+KIxxr2qjkmuVbVK8k5yyNTocFNVtyTPTO9UydQ24jwH0CPJfh7fJblU1WmeY/vDbcAi/GYOC6iq1xhjvfQ6oDNXfAC0pIICoCUVFAAtCSgAWhJQALQkoABoSUAB0NIHaFoMHwI+U/wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(211)\n",
    "plt.plot(history['categorical_accuracy'])\n",
    "plt.plot(history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val'],loc='upper left')# summarize history for loss \n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val'],loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "neural-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = model.get_next_batch(2000, file_path = test_files) # Grab 2000 files from Test files for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "brown-figure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 87.7%, Validation loss = 0.439979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.877, 0.43997857)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(data, label) # Evaluate on Data # Please note "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-production",
   "metadata": {},
   "source": [
    "# Let us See the Accuracy on Test Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "wireless-humor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model accuracy is 87.572494% (Number of test samples=9656)\n"
     ]
    }
   ],
   "source": [
    "grab = int(len(test_files)/5)\n",
    "fro = 0\n",
    "correct = 0\n",
    "for i in range(5):\n",
    "    data, label = model.get_next_batch(int(len(test_files)/5), test_files[fro:grab])\n",
    "    predictions = model.predict(data)[0]\n",
    "    correct+=np.sum(predictions == label)\n",
    "    fro = grab\n",
    "    grab+=int(len(test_files)/5)\n",
    "print(' Model accuracy is %f%% (Number of test samples=%d)' % (\n",
    "        (correct * 100) / len(test_files), len(test_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-inside",
   "metadata": {},
   "source": [
    "# Here we are Saving the Model for a reload using tf.saved_model.load, Serving Signature is set to Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "classified-automation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpath/model_checkpoint.ckpt-15000\n",
      "WARNING:tensorflow:From /home/jovyan/train.py:434: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: Model/model_pb/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "model.save_pb_model(file_name = \"Model/model_pb\",  first_conv_filter=128, second_conv_filter=64, frequency_size=40, time_size=49, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-blond",
   "metadata": {},
   "source": [
    "# The Next Lines of code introduces you to TensorFlow LITE (TFLITE) and Tensorflow LITE MICRO (TFLITE MICRO)\n",
    "### TFLITE for Android Devices and Micro-Computers\n",
    "### TFLITE Micro for Micro-controllers and Embedded Devices with low power and generally requiring int8 computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "convinced-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories and tflite micro libraries\n",
    "from tflite_op import *\n",
    "rep_size = 100\n",
    "float_model_tflite=\"Model/tfFloat\"\n",
    "quant_model_tflite= \"Model/tflite\"\n",
    "pb_model_dir = \"Model/model_pb\"\n",
    "tflite_micro = \"Model/tflite_micro.cc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "advisory-chest",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Invoking the TF1 implementation of TFLiteConverter because eager is disabled. Consider enabling eager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: Reshape_3:0, shape: (1, 1960), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: Reshape_3:0, shape: (1, 1960), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: labels_softmax:0, shape: (1, 38), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: labels_softmax:0, shape: (1, 38), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/lite/python/util.py:326: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/lite/python/util.py:326: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/python/framework/convert_to_constants.py:856: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/python/framework/convert_to_constants.py:856: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: Reshape_3:0, shape: (1, 1960), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: Reshape_3:0, shape: (1, 1960), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: labels_softmax:0, shape: (1, 38), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: labels_softmax:0, shape: (1, 38), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float model is 6259680 bytes\n"
     ]
    }
   ],
   "source": [
    "# See tflite_op for implementation. Save TFLITE MODEL FOR FLOAT VALUE COMPUTATION\n",
    "save_float_model(model_path=pb_model_dir, save_path=float_model_tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "wooden-maintenance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Invoking the TF1 implementation of TFLiteConverter because eager is disabled. Consider enabling eager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: Reshape_3:0, shape: (1, 1960), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: Reshape_3:0, shape: (1, 1960), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: labels_softmax:0, shape: (1, 38), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: labels_softmax:0, shape: (1, 38), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: Reshape_3:0, shape: (1, 1960), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: Reshape_3:0, shape: (1, 1960), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output tensors info: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: labels_softmax:0, shape: (1, 38), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: tensor name: labels_softmax:0, shape: (1, 38), type: DT_FLOAT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Model/model_pb/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model is 1574064 bytes\n"
     ]
    }
   ],
   "source": [
    "# # See tflite_op for implementation. Save TFLITE MODEL FOR INT8 VALUE COMPUTATION\n",
    "save_quantized_model(model_path=pb_model_dir, save_path=quant_model_tflite, rep_files=test_files, rep_data=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-roller",
   "metadata": {},
   "source": [
    "# Now Let us Test the Accuracy from TFLITE... See Implmentation in tflite_op.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "mexican-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our data from our wanted commands\n",
    "commands_files =[]\n",
    "for com in [\"on\", \"off\", \"heater\", \"fan\", \"light\"]:\n",
    "    search_path = os.path.join(\"dataset\", com, '*.wav')\n",
    "    file = gfile.Glob(search_path)\n",
    "    np.random.shuffle(file)\n",
    "    commands_files += file\n",
    "# Preprocess using the Micro_process Implementation\n",
    "data, labels = model.get_next_batch(len(commands_files), commands_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-spine",
   "metadata": {},
   "source": [
    "# Great Result, 93% on our Wanted words with TFLITE saved as Float: See Result below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "congressional-pierre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Float model accuracy is 93.984962% (Number of test samples=9044)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "correct_predictions = 0\n",
    "for i in range(len(data)):\n",
    "    correct_predictions += (predict_float(data[i], float_model_tflite) == labels[i])\n",
    "   \n",
    "\n",
    "print(' Float model accuracy is %f%% (Number of test samples=%d)' % (\n",
    "        (correct_predictions * 100) / len(data), len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-incentive",
   "metadata": {},
   "source": [
    "# Great Result, 93% on our Wanted words with TFLITE saved as INT8: See Result below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "funky-september",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Int8 model accuracy is 93.841221% (Number of test samples=9044)\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "for i in range(len(data)):\n",
    "    correct_predictions += (predict_quantized(data[i], quant_model_tflite ) == labels[i])\n",
    "   \n",
    "\n",
    "print(' Int8 model accuracy is %f%% (Number of test samples=%d)' % (\n",
    "        (correct_predictions * 100) / len(data), len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-shuttle",
   "metadata": {},
   "source": [
    "## For Embedded Devices, Let us covert to TFLITE Micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "atlantic-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i {quant_model_tflite} > {tflite_micro}\n",
    "REPLACE_TEXT = quant_model_tflite.replace('/', '_').replace('.', '_')\n",
    "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {tflite_micro}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-sessions",
   "metadata": {},
   "source": [
    "# Holla!!! You have Just Created a MODEL that can be deployed for Speech Recognition on Embedded Devices. Next is to locate the file Model/tflite_micro.cc and this is the Model for deployment to our Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "martial-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also copy the Parameters by running this Cell\n",
    "# !cat {MODEL_TFLITE_MICRO}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "civilian-virtue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: Model/ (stored 0%)\n",
      "  adding: Model/tflite_micro.cc (deflated 77%)\n",
      "  adding: Model/tflite (deflated 16%)\n",
      "  adding: Model/model_pb/ (stored 0%)\n",
      "  adding: Model/model_pb/variables/ (stored 0%)\n",
      "  adding: Model/model_pb/variables/variables.data-00000-of-00001 (deflated 7%)\n",
      "  adding: Model/model_pb/variables/variables.index (deflated 37%)\n",
      "  adding: Model/model_pb/saved_model.pb (deflated 87%)\n",
      "  adding: Model/tfFloat (deflated 7%)\n",
      "  adding: Model/.ipynb_checkpoints/ (stored 0%)\n",
      "  adding: Model/.ipynb_checkpoints/tflite_micro-checkpoint.cc (deflated 77%)\n"
     ]
    }
   ],
   "source": [
    "!zip model.zip -r Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "subject-course",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: checkpath/ (stored 0%)\n",
      "  adding: checkpath/model.pbtxt (deflated 95%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-12000.meta (deflated 87%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-15000.data-00000-of-00001 (deflated 7%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-13000.index (deflated 37%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-15000.meta (deflated 87%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-15000.index (deflated 37%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-11000.data-00000-of-00001 (deflated 7%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-13000.meta (deflated 87%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-14000.meta (deflated 87%)\n",
      "  adding: checkpath/checkpoint (deflated 80%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-14000.index (deflated 37%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-13000.data-00000-of-00001 (deflated 7%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-11000.index (deflated 37%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-11000.meta (deflated 87%)\n",
      "  adding: checkpath/.ipynb_checkpoints/ (stored 0%)\n",
      "  adding: checkpath/.ipynb_checkpoints/model-checkpoint.pbtxt (deflated 95%)\n",
      "  adding: checkpath/.ipynb_checkpoints/checkpoint-checkpoint (deflated 78%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-12000.data-00000-of-00001 (deflated 7%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-14000.data-00000-of-00001 (deflated 7%)\n",
      "  adding: checkpath/model_checkpoint.ckpt-12000.index (deflated 37%)\n",
      "  adding: checkpath/commands_labels.txt (deflated 34%)\n"
     ]
    }
   ],
   "source": [
    "!zip checkpoint.zip -r checkpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "specified-guarantee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  check.zip\n",
      "   creating: work/model/\n",
      "  inflating: work/model/model.pbtxt  \n",
      "  inflating: work/model/model_checkpoint.ckpt-7000.index  \n",
      "  inflating: work/model/model_checkpoint.ckpt-8000.meta  \n",
      "  inflating: work/model/model_checkpoint.ckpt-9000.meta  \n",
      "  inflating: work/model/model_checkpoint.ckpt-9000.index  \n",
      "  inflating: work/model/model_checkpoint.ckpt-8000.data-00000-of-00001  \n",
      "  inflating: work/model/model_checkpoint.ckpt-7000.data-00000-of-00001  \n",
      "  inflating: work/model/model_checkpoint.ckpt-8000.index  \n",
      "  inflating: work/model/checkpoint   \n",
      "  inflating: work/model/model_checkpoint.ckpt-9000.data-00000-of-00001  \n",
      "  inflating: work/model/model_checkpoint.ckpt-10000.data-00000-of-00001  \n",
      "  inflating: work/model/model_checkpoint.ckpt-6000.meta  \n",
      "  inflating: work/model/model_checkpoint.ckpt-6000.data-00000-of-00001  \n",
      "  inflating: work/model/model_checkpoint.ckpt-7000.meta  \n",
      "  inflating: work/model/model_checkpoint.ckpt-6000.index  \n",
      "  inflating: work/model/model_checkpoint.ckpt-10000.index  \n",
      "  inflating: work/model/commands_labels.txt  \n",
      "  inflating: work/model/model_checkpoint.ckpt-10000.meta  \n"
     ]
    }
   ],
   "source": [
    "!unzip check.zip -d work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-journal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-cisco",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-webmaster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-spending",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ()",
   "language": "python",
   "name": "lambda-stack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
